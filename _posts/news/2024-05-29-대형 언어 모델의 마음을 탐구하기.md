---
title: 대형 언어 모델의 마음을 탐구하기
date: 2024-05-29
category: news
layout: post
mermaid: true
---
출처 : [Mapping the Mind of a Large Language Model - Anthropic](https://www.anthropic.com)

# TL;DR
- 오늘날 우리는 AI 모델의 내부 작동 방식을 이해하는 데 있어 중요한 진전을 보고합니다. 우리는 배포된 대형 언어 모델 중 하나인 Claude Sonnet 내부에서 수백만 개의 개념이 어떻게 표현되는지 확인했습니다. 이는 현대의 생산 등급 대형 언어 모델 내부를 처음으로 자세히 살펴본 것입니다. 이러한 해석 가능성 발견은 미래에 AI 모델을 더 안전하게 만드는 데 도움이 될 수 있습니다.
- AI 모델을 블랙박스로 취급하는 경우가 많습니다. 입력이 들어가면 응답이 나오지만, 모델이 특정 응답을 제공한 이유는 명확하지 않습니다. 이는 이러한 모델이 안전하다는 것을 신뢰하기 어렵게 만듭니다. 내부 상태를 열어보는 것만으로는 도움이 되지 않습니다. 모델의 내부 상태는 명확한 의미 없이 숫자 목록(뉴런 활성화)으로 구성됩니다.
- 이전에는 뉴런 활성화 패턴을 인간이 해석할 수 있는 개념과 일치시키는 데 일부 진전을 이루었습니다. 우리는 사전 학습된 작은 언어 모델에 사전 학습 기법을 적용하여 대문자 텍스트, DNA 서열, 수학에서의 명사 등과 같은 개념에 해당하는 일관된 특징을 발견했습니다.
- 2023년 10월, 우리는 매우 작은 "장난감" 언어 모델에 사전 학습을 성공적으로 적용하여 일관된 특징을 발견했습니다. 그러나 이 모델은 매우 단순했습니다. 다른 연구자들은 이후 우리의 원래 연구보다 더 크고 복잡한 모델에 유사한 기술을 적용했습니다.
- 우리는 Claude 3.0 Sonnet의 중간 계층에서 수백만 개의 특징을 성공적으로 추출하여 계산 중간의 내부 상태에 대한 개략적인 개념 지도를 제공했습니다. 이는 현대의 생산 등급 대형 언어 모델 내부를 처음으로 자세히 살펴본 것입니다.
- 우리는 또한 이러한 특징을 조작하여 Claude의 응답이 어떻게 변하는지 확인했습니다. 예를 들어, "Golden Gate Bridge" 특징을 증폭하면 Claude는 자신을 "Golden Gate Bridge"라고 주장하는 등 이상한 응답을 하게 됩니다.
- 이러한 발견을 통해 AI 시스템의 위험한 행동을 모니터링하거나 원하는 결과로 유도하거나 특정 위험한 주제를 완전히 제거하는 데 사용할 수 있을 것입니다.

# 목차
- 서론
- AI 모델의 블랙박스 문제
- 사전 학습 기법의 적용
- Claude Sonnet의 내부 상태 분석
- 특징 조작 실험
- 안전성 향상을 위한 응용
- 결론 및 향후 연구 방향

# 서론
- 오늘날 우리는 AI 모델의 내부 작동 방식을 이해하는 데 있어 중요한 진전을 보고합니다. 우리는 배포된 대형 언어 모델 중 하나인 Claude Sonnet 내부에서 수백만 개의 개념이 어떻게 표현되는지 확인했습니다. 이는 현대의 생산 등급 대형 언어 모델 내부를 처음으로 자세히 살펴본 것입니다. 이러한 해석 가능성 발견은 미래에 AI 모델을 더 안전하게 만드는 데 도움이 될 수 있습니다.

# AI 모델의 블랙박스 문제
- AI 모델을 블랙박스로 취급하는 경우가 많습니다. 입력이 들어가면 응답이 나오지만, 모델이 특정 응답을 제공한 이유는 명확하지 않습니다. 이는 이러한 모델이 안전하다는 것을 신뢰하기 어렵게 만듭니다. 내부 상태를 열어보는 것만으로는 도움이 되지 않습니다. 모델의 내부 상태는 명확한 의미 없이 숫자 목록(뉴런 활성화)으로 구성됩니다.

# 사전 학습 기법의 적용
- 이전에는 뉴런 활성화 패턴을 인간이 해석할 수 있는 개념과 일치시키는 데 일부 진전을 이루었습니다. 우리는 사전 학습된 작은 언어 모델에 사전 학습 기법을 적용하여 대문자 텍스트, DNA 서열, 수학에서의 명사 등과 같은 개념에 해당하는 일관된 특징을 발견했습니다.
- 2023년 10월, 우리는 매우 작은 "장난감" 언어 모델에 사전 학습을 성공적으로 적용하여 일관된 특징을 발견했습니다. 그러나 이 모델은 매우 단순했습니다. 다른 연구자들은 이후 우리의 원래 연구보다 더 크고 복잡한 모델에 유사한 기술을 적용했습니다.

# Claude Sonnet의 내부 상태 분석
- 우리는 Claude 3.0 Sonnet의 중간 계층에서 수백만 개의 특징을 성공적으로 추출하여 계산 중간의 내부 상태에 대한 개략적인 개념 지도를 제공했습니다. 이는 현대의 생산 등급 대형 언어 모델 내부를 처음으로 자세히 살펴본 것입니다.
- 우리는 도시(샌프란시스코), 사람(로잘린드 프랭클린), 원소(리튬), 과학 분야(면역학), 프로그래밍 구문(함수 호출) 등 다양한 엔티티에 해당하는 특징을 발견했습니다. 이러한 특징은 다중 모드 및 다중 언어로, 여러 언어로 된 이름이나 설명뿐만 아니라 해당 엔티티의 이미지에도 반응합니다.
![이미지명](https://www-cdn.anthropic.com/images/4zrzovbb/website/80d6e033480704f5d57fbae4e3f0368d86a747ae-5761x3240.png)

# 특징 조작 실험
- 우리는 또한 이러한 특징을 조작하여 Claude의 응답이 어떻게 변하는지 확인했습니다. 예를 들어, "Golden Gate Bridge" 특징을 증폭하면 Claude는 자신을 "Golden Gate Bridge"라고 주장하는 등 이상한 응답을 하게 됩니다.
- 우리는 Claude가 스팸 이메일을 읽을 때 활성화되는 특징을 발견했습니다. 이 특징을 인위적으로 활성화하면 Claude는 스팸 이메일을 작성하게 됩니다.
![이미지명](https://www-cdn.anthropic.com/images/4zrzovbb/website/c896a301ad3d1ef4237cb05b68d78b467c444097-2200x1284.png)

# 안전성 향상을 위한 응용
- 이러한 발견을 통해 AI 시스템의 위험한 행동을 모니터링하거나 원하는 결과로 유도하거나 특정 위험한 주제를 완전히 제거하는 데 사용할 수 있을 것입니다.
- 우리는 또한 헌법적 AI와 같은 다른 안전 기술을 강화하여 모델이 더 무해하고 정직한 행동으로 전환되는 방식을 이해하고 프로세스의 격차를 식별할 수 있을 것입니다.
![이미지명](https://www-cdn.anthropic.com/images/4zrzovbb/website/2ff94c622f3d65bc3038cc154006d2be515fa2d7-2200x1660.png)

# 결론 및 향후 연구 방향
- Anthropic은 모델을 깊이 이해하는 것이 모델을 더 안전하게 만드는 데 도움이 될 것이라고 믿기 때문에 해석 가능성 연구에 상당한 투자를 해왔습니다. 이 새로운 연구는 공개적으로 배포된 대형 언어 모델에 기계적 해석 가능성을 적용한 중요한 이정표를 나타냅니다.
- 그러나 작업은 이제 막 시작되었습니다. 우리가 발견한 특징은 모델이 훈련 중에 학습한 모든 개념의 작은 부분 집합을 나타내며, 현재 기술을 사용하여 전체 특징 세트를 찾는 것은 비용이 많이 듭니다.
- 모델이 사용하는 표현을 이해하는 것은 그것을 어떻게 사용하는지 알려주지 않습니다. 우리는 여전히 회로를 찾아야 하며, 우리가 발견한 안전 관련 특징이 실제로 안전을 개선하는 데 사용할 수 있는지 보여주어야 합니다. 할 일이 많습니다.
![이미지명](https://www-cdn.anthropic.com/images/4zrzovbb/website/fe4d42c004bf43efda0f5921adfedd2f8f42e417-2200x2140.png)

- 자세한 내용은 논문 "Scaling Monosemanticity: Extracting Interpretable Features from Claude 3 Sonnet"을 참조하십시오.
- AI 모델을 해석하고 개선하는 데 관심이 있는 분들은 저희 팀의 공개 채용 공고를 확인해 주세요. 매니저, 연구 과학자, 연구 엔지니어를 찾고 있습니다.
![이미지명](https://www-cdn.anthropic.com/images/4zrzovbb/website/4effa33dab919f9bc1779848d5c8abd5405f2275-2200x1320.png)