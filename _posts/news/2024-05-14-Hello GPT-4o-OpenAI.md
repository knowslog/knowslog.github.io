---
title: Hello GPT-4o
date: 2024-05-14
category: news
layout: post
mermaid: true
---
출처: [Hello GPT-4o-OpenAI](https://openai.com/index/hello-gpt-4o/)

# TL;DR
OpenAI가 GPT-4o를 발표했습니다. 이 새로운 플래그십 모델은 실시간으로 텍스트, 음성, 이미지 데이터를 처리할 수 있습니다. GPT-4o는 더 자연스러운 인간-컴퓨터 상호작용을 목표로 하며, 텍스트, 음성, 이미지 입력을 결합하여 처리하고, 더 빠르고 저렴하게 사용할 수 있습니다.

## 목차
- GPT-4o 소개
- 모델 기능
- 새로운 데모
- 향후 계획

# GPT-4o 소개
GPT-4o는 "omni"를 의미하며, 텍스트, 음성, 이미지 입력을 결합하여 처리할 수 있는 새로운 플래그십 모델입니다. 실시간으로 텍스트, 음성, 이미지 출력을 생성하며, 응답 시간은 평균 320밀리초로 인간의 반응 시간과 유사합니다. GPT-4 Turbo와 비슷한 성능을 자랑하며, 비영어 텍스트에서 더 높은 성능을 보이고, API 비용은 50% 저렴합니다. 특히 비전과 음성 이해 능력이 뛰어납니다.

# 모델 기능
GPT-4o는 텍스트, 음성, 이미지 데이터를 실시간으로 처리할 수 있으며, 다양한 입력과 출력을 결합할 수 있습니다. 이전 GPT 모델과 달리, 모든 입력과 출력을 단일 신경망으로 처리하여 더 자연스러운 상호작용이 가능합니다. GPT-4o는 고급 비전과 음성 이해 기능을 가지고 있으며, 다양한 분야에서 활용될 수 있습니다.

# 새로운 데모
GPT-4o의 기능을 시연하는 여러 데모가 있습니다. 예를 들어, 로봇이 타자기를 사용하는 장면, 여러 스피커와의 미팅 요약, 3D 객체 합성 등이 포함되어 있습니다. 이 데모들은 GPT-4o의 다양한 기능과 가능성을 보여줍니다.

# 향후 계획
GPT-4o는 아직 초기 단계에 있으며, OpenAI는 이 모델의 잠재력을 탐구하고 발전시키기 위해 지속적으로 노력할 것입니다. 더 많은 연구와 개발을 통해 GPT-4o의 기능을 확장하고, 다양한 분야에서의 적용 가능성을 높일 계획입니다.
